{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Decision Trees and Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entropy Function\n",
    "\n",
    "This function calculates the entropy of a given dataset based on the target column 'hospital_death'.\n",
    "Entropy is a measure of impurity or disorder in a dataset.\n",
    "\n",
    "**Formula:** E = - sum(p_i * log2(p_i)) for all classes i.\n",
    "\n",
    "For a binary classification problem with target 'hospital_death' (classes 0 and 1):\n",
    "E = - (p_0 * log2(p_0) + p_1 * log2(p_1))\n",
    "where p_0 is the proportion of class 0 (e.g., not survived) and p_1 is the proportion of class 1 (e.g., survived).\n",
    "\n",
    "If a proportion p_i is 0, then p_i * log2(p_i) is taken as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    \"\"\"\n",
    "    Calculates the entropy of a dataset based on the 'hospital_death' target column.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing the dataset with a 'hospital_death' column.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated entropy value.\n",
    "               Returns 0 if the dataset is empty or the target column has no variance (all same class).\n",
    "    \"\"\"\n",
    "    target_column = 'hospital_death'\n",
    "    \n",
    "    if data.empty or target_column not in data.columns:\n",
    "        # print(\"Warning: Data is empty or target column missing for entropy calculation.\")\n",
    "        return 0.0\n",
    "    \n",
    "    counts = data[target_column].value_counts()\n",
    "    total_count = len(data[target_column])\n",
    "    \n",
    "    if total_count == 0 or len(counts) <= 1: # No variance or empty\n",
    "        # print(\"Warning: Total count is 0 or only one class present for entropy calculation.\")\n",
    "        return 0.0\n",
    "        \n",
    "    entropy_value = 0.0\n",
    "    for count_val in counts:\n",
    "        proportion = count_val / total_count\n",
    "        if proportion > 0: # log2(0) is undefined, but 0 * log2(0) limit is 0\n",
    "            entropy_value -= proportion * np.log2(proportion)\n",
    "            \n",
    "    return entropy_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage for Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "sample_data_for_lab2 = {\n",
    "    'age': [25, 30, 35, 40, 45, 50, 55, 60],\n",
    "    'gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'],\n",
    "    'hospital_death': [0, 1, 0, 0, 1, 1, 0, 1] # 4 survived (1), 4 not survived (0)\n",
    "}\n",
    "sample_df_lab2 = pd.DataFrame(sample_data_for_lab2)\n",
    "\n",
    "entropy_val_lab2 = entropy(sample_df_lab2)\n",
    "print(f\"Sample DataFrame for Lab 2:\\n{sample_df_lab2}\")\n",
    "print(f\"\\nCalculated Entropy for sample_df_lab2: {entropy_val_lab2:.4f}\") # Should be 1.0 for a 50/50 split\n",
    "\n",
    "# Example with all same class (entropy should be 0)\n",
    "sample_data_all_same = {\n",
    "    'hospital_death': [0, 0, 0, 0]\n",
    "}\n",
    "sample_df_all_same = pd.DataFrame(sample_data_all_same)\n",
    "entropy_all_same = entropy(sample_df_all_same)\n",
    "print(f\"\\nSample DataFrame (all same class):\\n{sample_df_all_same}\")\n",
    "print(f\"Calculated Entropy (all same class): {entropy_all_same:.4f}\")\n",
    "\n",
    "# Example with empty data\n",
    "empty_df = pd.DataFrame({'hospital_death': []})\n",
    "entropy_empty = entropy(empty_df)\n",
    "print(f\"\\nSample DataFrame (empty):\\n{empty_df}\")\n",
    "print(f\"Calculated Entropy (empty): {entropy_empty:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Information Gain Function\n",
    "\n",
    "This function calculates the information gain of a split on a dataset. \n",
    "Information gain is the reduction in entropy achieved by partitioning the data according to a given attribute (represented by the mask).\n",
    "\n",
    "**Formula:** IG(S, A) = Entropy(S) - sum over v in Values(A) ( |S_v| / |S| * Entropy(S_v) )\n",
    "\n",
    "Where:\n",
    "- S is the original dataset.\n",
    "- A is the attribute (or mask) used for splitting.\n",
    "- Values(A) are the possible values of attribute A (here, True/False from the mask representing the two subsets).\n",
    "- S_v is the subset of S for which attribute A has value v.\n",
    "- |S_v| is the number of instances in subset S_v.\n",
    "- |S| is the total number of instances in S.\n",
    "\n",
    "For a binary split (left and right subsets based on the mask):\n",
    "IG = Entropy(parent) - [ (weight_left * Entropy(left_subset)) + (weight_right * Entropy(right_subset)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(data, mask):\n",
    "    \"\"\"\n",
    "    Calculates the information gain from partitioning the data using a boolean mask.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The dataset (parent node) containing 'hospital_death' column.\n",
    "        mask (pd.Series): A boolean Series of the same length as data.\n",
    "                          True indicates the instance goes to the left subset,\n",
    "                          False indicates the instance goes to the right subset.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated information gain.\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        # print(\"Warning: Data is empty for information gain calculation.\")\n",
    "        return 0.0\n",
    "\n",
    "    parent_entropy = entropy(data)\n",
    "    \n",
    "    left_subset = data[mask]\n",
    "    right_subset = data[~mask]\n",
    "    \n",
    "    total_count = len(data)\n",
    "    count_left = len(left_subset)\n",
    "    count_right = len(right_subset)\n",
    "    \n",
    "    if total_count == 0: # Should be caught by data.empty, but as a safeguard\n",
    "        # print(\"Warning: Total count is 0 in information gain.\")\n",
    "        return 0.0 \n",
    "    \n",
    "    # Handle cases where a subset might be empty, its entropy is 0 and its weight will correctly make its contribution 0.\n",
    "    entropy_left = entropy(left_subset)\n",
    "    entropy_right = entropy(right_subset)\n",
    "    \n",
    "    weight_left = count_left / total_count if total_count > 0 else 0\n",
    "    weight_right = count_right / total_count if total_count > 0 else 0\n",
    "    \n",
    "    weighted_children_entropy = (weight_left * entropy_left) + (weight_right * entropy_right)\n",
    "    \n",
    "    ig = parent_entropy - weighted_children_entropy\n",
    "    \n",
    "    return ig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage for Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sample_df_lab2 from the entropy example\n",
    "print(f\"Original DataFrame for Information Gain Example:\\n{sample_df_lab2}\")\n",
    "parent_entropy_for_ig_example = entropy(sample_df_lab2)\n",
    "print(f\"Parent Entropy: {parent_entropy_for_ig_example:.4f}\")\n",
    "\n",
    "# Create a sample mask, e.g., based on 'age' > 37\n",
    "sample_mask = sample_df_lab2['age'] > 37\n",
    "print(f\"\\nSample Mask (age > 37):\\n{sample_mask.values}\")\n",
    "\n",
    "left_subset_example = sample_df_lab2[sample_mask]\n",
    "right_subset_example = sample_df_lab2[~sample_mask]\n",
    "\n",
    "print(f\"\\nLeft Subset (age > 37):\\n{left_subset_example}\")\n",
    "entropy_left_example = entropy(left_subset_example)\n",
    "print(f\"Entropy of Left Subset: {entropy_left_example:.4f}\")\n",
    "\n",
    "print(f\"\\nRight Subset (age <= 37):\\n{right_subset_example}\")\n",
    "entropy_right_example = entropy(right_subset_example)\n",
    "print(f\"Entropy of Right Subset: {entropy_right_example:.4f}\")\n",
    "\n",
    "ig_value = information_gain(sample_df_lab2, sample_mask)\n",
    "print(f\"\\nCalculated Information Gain for 'age > 37': {ig_value:.4f}\")\n",
    "\n",
    "# Another mask example: gender == 'Male'\n",
    "sample_mask_gender = sample_df_lab2['gender'] == 'Male'\n",
    "print(f\"\\nSample Mask (gender == 'Male'):\\n{sample_mask_gender.values}\")\n",
    "ig_value_gender = information_gain(sample_df_lab2, sample_mask_gender)\n",
    "print(f\"Calculated Information Gain for 'gender == \\\"Male\\\"': {ig_value_gender:.4f}\")\n",
    "\n",
    "# Example with a mask that perfectly separates classes (if possible with this data)\n",
    "# For sample_df_lab2, 'hospital_death' is [0, 1, 0, 0, 1, 1, 0, 1]\n",
    "# Let's try a mask that might give high IG, e.g., age > 40 (targets: [1,1,0,1]) vs age <=40 (targets: [0,1,0,0])\n",
    "perfect_ish_mask = sample_df_lab2['age'] > 40\n",
    "print(f\"\\nSample Mask (age > 40):\\n{perfect_ish_mask.values}\")\n",
    "ig_value_perfect_ish = information_gain(sample_df_lab2, perfect_ish_mask)\n",
    "left_subset_p = sample_df_lab2[perfect_ish_mask]\n",
    "right_subset_p = sample_df_lab2[~perfect_ish_mask]\n",
    "print(f\"Left (age > 40) 'hospital_death': {left_subset_p['hospital_death'].tolist()}, Entropy: {entropy(left_subset_p):.4f}\")\n",
    "print(f\"Right (age <= 40) 'hospital_death': {right_subset_p['hospital_death'].tolist()}, Entropy: {entropy(right_subset_p):.4f}\")\n",
    "print(f\"Calculated Information Gain for 'age > 40': {ig_value_perfect_ish:.4f}\")\n",
    "\n",
    "# Example with an empty dataframe for information_gain\n",
    "ig_empty = information_gain(empty_df, pd.Series([], dtype=bool))\n",
    "print(f\"\\nInformation Gain for empty DataFrame: {ig_empty:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find Best Split Function (Basic Implementation)\n",
    "\n",
    "This function iterates through all features (excluding the target 'hospital_death') and their possible split points to find the split that maximizes information gain.\n",
    "\n",
    "For the 'basic' implementation:\n",
    "- It processes features that are numeric (or can be meaningfully compared for thresholds).\n",
    "- For each such feature, it sorts its unique values.\n",
    "- Potential thresholds are calculated as the midpoint between consecutive unique sorted values.\n",
    "- It uses the `information_gain` function to evaluate each split.\n",
    "- It returns the best information gain found, along with the corresponding feature and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data, impl_part='basic'):\n",
    "    \"\"\"\n",
    "    Finds the best feature and threshold to split the data on, maximizing information gain.\n",
    "    'basic' implementation: Considers only numeric features for splitting.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The dataset, including 'hospital_death' target column.\n",
    "        impl_part (str): Implementation part, currently 'basic'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (best_ig, best_threshold, best_feature)\n",
    "               Returns (-1, None, None) if no valid split is found or data is unsuitable.\n",
    "    \"\"\"\n",
    "    best_ig = -1.0  # Initialize with a value lower than any possible IG\n",
    "    best_threshold = None\n",
    "    best_feature = None\n",
    "\n",
    "    if data.empty or 'hospital_death' not in data.columns or len(data) < 2:\n",
    "        return best_ig, best_threshold, best_feature\n",
    "\n",
    "    # Exclude the target column from features to split on\n",
    "    features = data.columns.drop('hospital_death', errors='ignore')\n",
    "\n",
    "    for feature in features:\n",
    "        # For 'basic' part, only consider numeric features for threshold splitting\n",
    "        if not pd.api.types.is_numeric_dtype(data[feature]):\n",
    "            # print(f\"Skipping non-numeric feature '{feature}' in basic mode.\")\n",
    "            continue\n",
    "            \n",
    "        unique_values = sorted(data[feature].unique())\n",
    "        \n",
    "        if len(unique_values) < 2: # Cannot split if only one unique value\n",
    "            continue\n",
    "\n",
    "        for i in range(len(unique_values) - 1):\n",
    "            val1 = unique_values[i]\n",
    "            val2 = unique_values[i+1]\n",
    "            \n",
    "            # This check is mostly for safety, unique_values should not have duplicates here\n",
    "            if val1 == val2:\n",
    "                continue\n",
    "                \n",
    "            threshold = (val1 + val2) / 2.0\n",
    "            \n",
    "            # Create mask based on the current feature and threshold\n",
    "            mask = data[feature] <= threshold\n",
    "            \n",
    "            # If mask results in all True or all False, it's not a useful split\n",
    "            if mask.all() or (~mask).all():\n",
    "                continue\n",
    "\n",
    "            current_ig = information_gain(data, mask)\n",
    "\n",
    "            if current_ig > best_ig:\n",
    "                best_ig = current_ig\n",
    "                best_threshold = threshold\n",
    "                best_feature = feature\n",
    "                \n",
    "    return best_ig, best_threshold, best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage for find_best_split (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using sample_df_lab2 for find_best_split example:\")\n",
    "print(sample_df_lab2)\n",
    "\n",
    "best_ig_basic, best_thresh_basic, best_feat_basic = find_best_split(sample_df_lab2, 'basic')\n",
    "\n",
    "print(f\"\\nBest Information Gain (Basic): {best_ig_basic:.4f}\")\n",
    "print(f\"Best Threshold (Basic): {best_thresh_basic}\")\n",
    "print(f\"Best Feature (Basic): {best_feat_basic}\")\n",
    "\n",
    "# Example with a slightly more complex numeric dataset\n",
    "complex_data = {\n",
    "    'feature1': [10, 15, 20, 25, 30, 35, 40, 45, 50, 55], # Clear split potential\n",
    "    'feature2': [1, 1, 0, 0, 1, 1, 0, 0, 1, 1], # Less clear\n",
    "    'hospital_death': [0, 0, 0, 0, 1, 1, 1, 1, 1, 1] # Target split at midpoint of feature1\n",
    "}\n",
    "complex_df = pd.DataFrame(complex_data)\n",
    "print(f\"\\nComplex DataFrame:\\n{complex_df}\")\n",
    "\n",
    "best_ig_complex, best_thresh_complex, best_feat_complex = find_best_split(complex_df, 'basic')\n",
    "print(f\"\\nBest Information Gain (Complex): {best_ig_complex:.4f}\")\n",
    "print(f\"Best Threshold (Complex): {best_thresh_complex}\")\n",
    "print(f\"Best Feature (Complex): {best_feat_complex}\")\n",
    "\n",
    "# Example with no possible split yielding positive IG (or only one class in data)\n",
    "no_gain_data = {\n",
    "    'feature1': [10, 20, 30],\n",
    "    'hospital_death': [0, 0, 0]\n",
    "}\n",
    "no_gain_df = pd.DataFrame(no_gain_data)\n",
    "print(f\"\\nNo Gain DataFrame:\\n{no_gain_df}\")\n",
    "best_ig_no_gain, _, _ = find_best_split(no_gain_df, 'basic')\n",
    "print(f\"Best IG (No Gain Data): {best_ig_no_gain:.4f}\") # Parent entropy is 0, so IG will be 0\n",
    "\n",
    "# Example with empty data for find_best_split\n",
    "best_ig_empty_fbs, _, _ = find_best_split(empty_df, 'basic')\n",
    "print(f\"\\nBest IG (Empty Data for find_best_split): {best_ig_empty_fbs:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6" 
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
